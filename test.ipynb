{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prabh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\prabh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing C:\\Users\\prabh\\Smart-pruner-dev\\pruning\\unstructured\\L1norm.py\n",
      "Importing C:\\Users\\prabh\\Smart-pruner-dev\\pruning\\unstructured\\train.py\n",
      "Importing C:\\Users\\prabh\\Smart-pruner-dev\\pruning\\unstructured\\train.py\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "from datasets import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pruning.unstructured import *\n",
    "\n",
    "#has to import eval metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = Lenet()\n",
    "mnist= MNIST()\n",
    "train_dataloader, _ = mnist.get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lenet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[-0.0233,  0.1106,  0.1920, -0.1157, -0.1862],\n",
      "          [ 0.1626,  0.1027, -0.1846,  0.1929,  0.1350],\n",
      "          [ 0.0780, -0.1519,  0.0933, -0.1273,  0.0290],\n",
      "          [ 0.1166, -0.1459, -0.1400, -0.1546,  0.1799],\n",
      "          [ 0.0292,  0.0921,  0.0094,  0.1739,  0.0467]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0673, -0.1937,  0.0150, -0.0135,  0.1546],\n",
      "          [-0.0288,  0.0129, -0.1814, -0.1603, -0.1347],\n",
      "          [ 0.0555, -0.0850, -0.1228,  0.0139, -0.0909],\n",
      "          [-0.1346,  0.1434, -0.0749, -0.0999, -0.1721],\n",
      "          [ 0.0184,  0.0937,  0.1704,  0.0948,  0.1250]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0443,  0.0657,  0.0769,  0.1199,  0.1052],\n",
      "          [-0.0823, -0.0582, -0.1509, -0.1621, -0.1319],\n",
      "          [-0.1784, -0.1420,  0.0290, -0.0590, -0.1046],\n",
      "          [-0.1422,  0.0091,  0.1955,  0.0999, -0.0006],\n",
      "          [-0.0921,  0.1302,  0.0819, -0.1083, -0.1808]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1206,  0.1892, -0.1783,  0.1600, -0.1000],\n",
      "          [ 0.0696, -0.1271,  0.1595, -0.1738, -0.0422],\n",
      "          [ 0.0494,  0.0891, -0.1782, -0.0575,  0.1525],\n",
      "          [-0.1095, -0.1755, -0.0825, -0.0756, -0.1494],\n",
      "          [-0.1698, -0.1752,  0.1040, -0.0565, -0.0789]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0101, -0.1204, -0.1680,  0.0369,  0.0282],\n",
      "          [ 0.1081,  0.1686, -0.0294,  0.0816,  0.0132],\n",
      "          [ 0.0940, -0.1716,  0.1998,  0.1854, -0.1684],\n",
      "          [-0.1383,  0.0336, -0.0254, -0.1056,  0.0979],\n",
      "          [ 0.0916, -0.0531, -0.1473, -0.1129, -0.1392]]],\n",
      "\n",
      "\n",
      "        [[[-0.1420,  0.1429, -0.1639, -0.0575,  0.1135],\n",
      "          [ 0.1816, -0.1520,  0.0544, -0.0218, -0.1279],\n",
      "          [ 0.1887,  0.0984, -0.1972,  0.1800, -0.0959],\n",
      "          [-0.0905, -0.1915,  0.1067,  0.0875,  0.1007],\n",
      "          [-0.1180, -0.0070,  0.0047, -0.0216, -0.0411]]]], requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.1898,  0.1178, -0.1357,  0.0444,  0.1425, -0.1808],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(lenet.conv1.named_parameters())) #before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5ab85b18274e4b8864830b1842f33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 4.4069 | \n",
      "Epoch: 2 | train_loss: 3.0324 | \n",
      "Epoch: 3 | train_loss: 2.5241 | \n",
      "Epoch: 4 | train_loss: 2.1993 | \n",
      "Epoch: 5 | train_loss: 1.9016 | \n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(lenet,5,train_dataloader,criterion,optimizer) \n",
    "loss =trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[ 1.0377e-02,  1.9199e-01,  2.6342e-01, -1.0098e-01, -2.5374e-01],\n",
      "          [ 2.0907e-01,  1.6116e-01, -1.1583e-01,  2.5863e-01,  8.4947e-02],\n",
      "          [ 1.2378e-01, -1.5181e-01,  7.2921e-02, -9.1868e-02,  2.5469e-02],\n",
      "          [ 1.3470e-01, -1.5497e-01, -1.7225e-01, -1.4863e-01,  2.1529e-01],\n",
      "          [ 1.6509e-02,  1.1905e-01,  4.4589e-02,  1.9053e-01,  5.5813e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2181e-01, -2.0451e-01, -9.9567e-03, -5.7863e-02,  8.4429e-02],\n",
      "          [-1.4915e-02, -4.3612e-02, -2.2327e-01, -2.2937e-01, -1.8159e-01],\n",
      "          [ 8.4670e-02, -1.2583e-01, -1.5268e-01, -1.5662e-02, -7.9464e-02],\n",
      "          [-6.5079e-02,  1.4520e-01, -7.2233e-02, -8.6229e-02, -6.0131e-02],\n",
      "          [ 1.3604e-01,  1.8377e-01,  2.7445e-01,  1.9818e-01,  2.3076e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0433e-01,  9.2068e-02,  1.1018e-01,  1.8690e-01,  1.8521e-01],\n",
      "          [-1.0056e-01, -9.4418e-02, -1.7914e-01, -1.5061e-01, -1.1722e-01],\n",
      "          [-1.9594e-01, -1.8633e-01, -2.3297e-02, -7.5065e-02, -1.2266e-01],\n",
      "          [-1.7762e-01, -6.4912e-02,  1.1630e-01,  4.3258e-02, -5.7942e-02],\n",
      "          [-1.2412e-01,  1.1562e-01,  5.6355e-02, -1.2421e-01, -1.8833e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2637e-01,  2.5962e-01, -9.6685e-02,  2.2581e-01, -1.5094e-02],\n",
      "          [ 1.2805e-01, -1.2928e-01,  1.5859e-01, -1.4240e-01, -3.4875e-02],\n",
      "          [ 4.6834e-02,  3.4203e-03, -2.4197e-01, -1.0806e-01,  7.4672e-02],\n",
      "          [-8.4284e-02, -2.3255e-01, -1.6862e-01, -1.3597e-01, -2.0362e-01],\n",
      "          [-5.6173e-02, -1.8123e-01,  2.7037e-02, -1.0388e-01, -6.8822e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1665e-02, -6.5175e-02, -1.0859e-01,  1.0149e-01,  1.0951e-01],\n",
      "          [ 1.5724e-01,  2.4299e-01,  5.9860e-02,  1.8826e-01,  1.3403e-01],\n",
      "          [ 1.4808e-01, -1.1998e-01,  2.8598e-01,  2.8932e-01, -9.1579e-02],\n",
      "          [-8.8611e-02,  5.7816e-02, -2.0179e-02, -1.4297e-01,  8.2846e-02],\n",
      "          [ 1.1277e-01, -6.8636e-02, -2.1903e-01, -1.9715e-01, -1.9656e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7581e-01,  1.0015e-01, -2.0503e-01, -1.0940e-01,  8.4370e-02],\n",
      "          [ 1.4150e-01, -1.9842e-01, -9.3391e-05, -1.0339e-01, -1.7769e-01],\n",
      "          [ 1.4406e-01,  6.7464e-02, -2.3978e-01,  1.1114e-01, -1.3730e-01],\n",
      "          [-1.5798e-01, -2.3852e-01,  6.2968e-02,  3.0357e-02,  6.8344e-02],\n",
      "          [-1.7340e-01, -3.5670e-02, -1.7483e-03, -3.0080e-02, -2.6751e-02]]]],\n",
      "       requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.1785,  0.0084, -0.2480, -0.0593,  0.0988, -0.2323],\n",
      "       requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(lenet.conv1.named_parameters())) #after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = UnstructuredL1normPrune(lenet,5,train_dataloader,criterion,optimizer,0.5)\n",
    "pruned_model = trainer.prune_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([-0.1785,  0.0084, -0.2480, -0.0593,  0.0988, -0.2323],\n",
      "       requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[[[ 0.0000,  0.1920,  0.2634, -0.0000, -0.2537],\n",
      "          [ 0.2091,  0.1612, -0.0000,  0.2586,  0.0000],\n",
      "          [ 0.1238, -0.1518,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.1347, -0.1550, -0.1722, -0.1486,  0.2153],\n",
      "          [ 0.0000,  0.1190,  0.0000,  0.1905,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1218, -0.2045, -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.2233, -0.2294, -0.1816],\n",
      "          [ 0.0000, -0.1258, -0.1527, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.1452, -0.0000, -0.0000, -0.0000],\n",
      "          [ 0.1360,  0.1838,  0.2745,  0.1982,  0.2308]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  0.1869,  0.1852],\n",
      "          [-0.0000, -0.0000, -0.1791, -0.1506, -0.0000],\n",
      "          [-0.1959, -0.1863, -0.0000, -0.0000, -0.1227],\n",
      "          [-0.1776, -0.0000,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.1241,  0.0000,  0.0000, -0.1242, -0.1883]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2264,  0.2596, -0.0000,  0.2258, -0.0000],\n",
      "          [ 0.1281, -0.1293,  0.1586, -0.1424, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.2420, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.2325, -0.1686, -0.1360, -0.2036],\n",
      "          [-0.0000, -0.1812,  0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000],\n",
      "          [ 0.1572,  0.2430,  0.0000,  0.1883,  0.1340],\n",
      "          [ 0.1481, -0.1200,  0.2860,  0.2893, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000, -0.1430,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.2190, -0.1972, -0.1966]]],\n",
      "\n",
      "\n",
      "        [[[-0.1758,  0.0000, -0.2050, -0.0000,  0.0000],\n",
      "          [ 0.1415, -0.1984, -0.0000, -0.0000, -0.1777],\n",
      "          [ 0.1441,  0.0000, -0.2398,  0.0000, -0.1373],\n",
      "          [-0.1580, -0.2385,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.1734, -0.0000, -0.0000, -0.0000, -0.0000]]]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(pruned_model.conv1.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
